{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "GAN APPROACH"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making flexible predictions : Normalizing the margins to uniform distributions using the empirical Cumulative Distribution Function (CDF), and then training a GAN to make flexible predictions in this normalized space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import xarray as xr\n",
    "import xskillscore as xs\n",
    "import skimage\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "path = \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/mberthier/repos/Downscaling_CM/utils\"\n",
    "os.chdir(path)\n",
    "import metrics\n",
    "import dataset\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "plt.rcParams['figure.dpi'] = 100 # 200 e.g. is really fine, but slower"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opening the files :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "path = \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/HadGEM_driven_COSMO/Present/2003\"\n",
    "os.chdir(path)\n",
    "filenames = dataset.getfiles()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing the margins : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Defining generator network\n",
    "generator = keras.Sequential([layers.Dense(256, input_shape=(latent_dim,)),  # Input layer with 256 units\n",
    "    layers.LeakyReLU(alpha=0.2),                   # Activation function\n",
    "    layers.Dense(512),                             # Hidden layer with 512 units\n",
    "    layers.LeakyReLU(alpha=0.2),                   # Activation function\n",
    "    layers.Dense(1024),                            # Hidden layer with 1024 units\n",
    "    layers.LeakyReLU(alpha=0.2),                   # Activation function\n",
    "    layers.Dense(num_features, activation='tanh')  # Output layer with tanh activation\n",
    "    ]) \n",
    "\n",
    "# Defining discriminator network\n",
    "discriminator = keras.Sequential([\n",
    "    layers.Dense(512, input_shape=(num_features,)),  # Input layer with 512 units\n",
    "    layers.LeakyReLU(alpha=0.2),                     # Activation function\n",
    "    layers.Dense(256),                               # Hidden layer with 256 units\n",
    "    layers.LeakyReLU(alpha=0.2),                     # Activation function\n",
    "    layers.Dense(1, activation='sigmoid')            # Output layer with sigmoid activation\n",
    "]) \n",
    "\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "# Defining discriminator loss function\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "#Defining generator loss function\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
