{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87299fd5-9b40-484f-b4a5-540d3c7a94f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9573487-8ccd-46a6-acef-dec444d2e60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embed_size, heads):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.heads = heads\n",
    "        self.head_dim = embed_size // heads\n",
    "\n",
    "        assert (\n",
    "            self.head_dim * heads == embed_size\n",
    "        ), \"Embedding size needs to be divisible by heads\"\n",
    "\n",
    "        self.values = nn.Linear(embed_size, embed_size)\n",
    "        self.keys = nn.Linear(embed_size, embed_size)\n",
    "        self.queries = nn.Linear(embed_size, embed_size)\n",
    "        self.fc_out = nn.Linear(embed_size, embed_size)\n",
    "\n",
    "    def forward(self, values, keys, query, mask):\n",
    "        N = query.shape[0] #batch size\n",
    "\n",
    "        value_len, key_len, query_len = values.shape[1], keys.shape[1], query.shape[1]#sentence length so number of features ?\n",
    "\n",
    "        values = self.values(values)  # (N, value_len, embed_size)\n",
    "        keys = self.keys(keys)  # (N, key_len, embed_size)\n",
    "        queries = self.queries(query)  # (N, query_len, embed_size)\n",
    "\n",
    "        \n",
    "        values = values.reshape(N, value_len, self.heads, self.head_dim)\n",
    "        keys = keys.reshape(N, key_len, self.heads, self.head_dim)\n",
    "        queries = queries.reshape(N, query_len, self.heads, self.head_dim)\n",
    "\n",
    "        energy = torch.einsum(\"nqhd,nkhd->nhqk\", [queries, keys])\n",
    "        # queries shape: (N, query_len, heads, heads_dim),\n",
    "        # keys shape: (N, key_len, heads, heads_dim)\n",
    "        # energy: (N, heads, query_len, key_len)\n",
    "\n",
    "        if mask is not None:\n",
    "            energy = energy.masked_fill(mask == 0, float(\"-1e20\"))\n",
    "\n",
    "        # Normalize energy values similarly to seq2seq + attention\n",
    "        # so that they sum to 1. Also divide by scaling factor for\n",
    "        # better stability\n",
    "        attention = torch.softmax(energy / (self.embed_size ** (1 / 2)), dim=3)\n",
    "        # attention shape: (N, heads, query_len, key_len)\n",
    "\n",
    "        out = torch.einsum(\"nhql,nlhd->nqhd\", [attention, values]).reshape(\n",
    "            N, query_len, self.heads * self.head_dim\n",
    "        )\n",
    "        # attention shape: (N, heads, query_len, key_len)\n",
    "        # values shape: (N, value_len, heads, heads_dim)\n",
    "        # out after matrix multiply: (N, query_len, heads, head_dim), then\n",
    "        # we reshape and flatten the last two dimensions.\n",
    "\n",
    "        out = self.fc_out(out)\n",
    "        # Linear layer doesn't modify the shape, final shape will be\n",
    "        # (N, query_len, embed_size)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbf0975b-3df2-4806-9c4d-8a239cf4dd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_size, heads, dropout, forward_expansion):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attention = SelfAttention(embed_size, heads)\n",
    "        self.norm1 = nn.LayerNorm(embed_size)\n",
    "        self.norm2 = nn.LayerNorm(embed_size)\n",
    "\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(embed_size, forward_expansion * embed_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(forward_expansion * embed_size, embed_size),\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, value, key, query, mask):\n",
    "        attention = self.attention(value, key, query, mask)\n",
    "\n",
    "        x = self.dropout(self.norm1(attention + query))\n",
    "        forward = self.feed_forward(x)\n",
    "        out = self.dropout(self.norm2(forward + x))\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba7b77f9-0ff5-49fe-a0bb-dcc156807e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbConv(nn.Module):\n",
    "    def __init__(self,embed_size):\n",
    "        super(EmbConv,self).__init__()\n",
    "        self.conv1=nn.Conv2d(4,embed_size,kernel_size=2,stride=1,padding=1,dilation=2) ##problème kernel_size=2 ça dépasse si pas dilatation=2\n",
    " \n",
    "    def forward(self,x):\n",
    "        x=self.conv1(x)\n",
    "        return x \n",
    "##Maintenant on a [batch_size,embed_size,h,w]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0eec1c6d-a1ed-4e68-99f1-945ab8ae680d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PersonalEncoder(nn.Module):\n",
    "    def __init__(self,full_data_size,embed_size,num_layer,heads,forward_expansion,dropout,max_length):\n",
    "        super(PersonalEncoder,self).__init__()\n",
    "        self.embed_size=embed_size\n",
    "        self.input_embedding=EmbConv(embed_size)\n",
    "        self.position_embedding=nn.Embedding(max_length,embed_size)\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                TransformerBlock(\n",
    "                    embed_size,\n",
    "                    heads,\n",
    "                    dropout=dropout,\n",
    "                    forward_expansion=forward_expansion,\n",
    "                )\n",
    "                for _ in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,x):\n",
    "        #x has size : [N,h,w,nb_features]\n",
    "        #Position encoding :\n",
    "        N,h,w,nb_features = x.shape\n",
    "        position = np.arange(1, h*w + 1).reshape(h, w)\n",
    "        position = np.tile(position, (N, 1, 1))\n",
    "        position = torch.from_numpy(position)\n",
    "\n",
    "        print('position size', position.size())\n",
    "        ##on doit rajouter le nbre_features : \n",
    "        #position = position.repeat(embed_size, 1,1,1)\n",
    "        #position = torch.permute(position,(1,2,3,0))\n",
    "\n",
    "        \n",
    "        \n",
    "        #Input embedding + position embedding : \n",
    "        #x needs to be size [N,channels,h,w] for CNN \n",
    "        x=x.numpy()\n",
    "        x=np.transpose(x, (0, 3, 1, 2))\n",
    "        x=torch.from_numpy(x)\n",
    "        print('x',x.size())\n",
    "        \n",
    "        #On remet x dans les dimensions initiales pour match the size of input_embedding : \n",
    "        x=self.input_embedding(x)\n",
    "        #print(\"Input_embedding has been done and x is size :\",x.size())\n",
    "        x=x.detach().numpy()\n",
    "        x=np.transpose(x, (0, 2, 3, 1))\n",
    "        x=torch.from_numpy(x)\n",
    "        #print(self.position_embedding(position).size())\n",
    "        ##position est de taille    \n",
    "\n",
    "        print(self.position_embedding.weight.size())\n",
    "        \n",
    "        out=self.dropout(x+self.position_embedding(position))\n",
    "        print(out.size()) #[N,h,w,embed_size]\n",
    "\n",
    "        ##Transformer block :\n",
    "        ##out must be size : [N,value_len,embed_size]\n",
    "        out = out.reshape(N, h * w, embed_size)\n",
    "        for layer in self.layers:\n",
    "            out = layer(out, out, out, mask=None)\n",
    "            #print(\"One more layer done and the size of the output is :\", out.size())\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6470eae8-5aaa-4af9-8358-691f74bc1768",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randint(0,20,(2,20,10,4)) #N=2,h=20,w=10,channels=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "34ae4db9-82fa-4338-9633-eb3377f7c239",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_size=1000\n",
    "embed_size=16\n",
    "num_layers=2\n",
    "forward_expansion=4\n",
    "heads=8\n",
    "dropout=0\n",
    "max_length=2000\n",
    "model=PersonalEncoder(full_data_size,embed_size,num_layers,heads,forward_expansion,dropout,max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a8177907-2716-4708-a45f-7ab796ab2f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = input.type(torch.float)\n",
    "#model(input)\n",
    "#input.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "68cdd56e-89de-4d3f-b04d-cd51a11ee652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 20, 10, 4])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_float = torch.randn((2,20,10,4)) #N=2,h=20,w=10,channels=4\n",
    "input_float.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0a941e8b-3c65-4988-ac84-4c86ab4d106e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position size torch.Size([2, 20, 10])\n",
      "x torch.Size([2, 4, 20, 10])\n",
      "torch.Size([2000, 16])\n",
      "torch.Size([2, 20, 10, 16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 200, 16])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input_float).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "10b8f219-2ba4-4906-8575-9057bb6b7330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position size torch.Size([2, 20, 10])\n",
      "x torch.Size([2, 4, 20, 10])\n",
      "torch.Size([2000, 16])\n",
      "torch.Size([2, 20, 10, 16])\n"
     ]
    }
   ],
   "source": [
    "intermediate=model(input_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6f536690-9cf9-4e9b-9dd5-e47143308e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(hidden_size)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out=out.detach().numpy()\n",
    "        out=np.transpose(out, (0, 2, 1))\n",
    "        out=torch.from_numpy(out) \n",
    "        out = self.batchnorm1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.dropout(out)\n",
    "        out=out.detach().numpy()\n",
    "        out=np.transpose(out, (0, 2, 1))\n",
    "        out=torch.from_numpy(out) \n",
    "        out = self.fc2(out)\n",
    "        out=out.detach().numpy()\n",
    "        out=np.transpose(out, (0, 2, 1))\n",
    "        out=torch.from_numpy(out) \n",
    "        out = self.batchnorm2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d79f18c6-62ff-41c8-86a3-27f73ad36134",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_model = MLP(input_size=embed_size, hidden_size=100, output_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ccd02578-6bb0-4245-bd81-d8d0feb10f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 20, 10, 4])\n",
      "taille de x en entrée : torch.Size([2, 20, 10, 4])\n",
      "position size torch.Size([2, 20, 10])\n",
      "x torch.Size([2, 4, 20, 10])\n",
      "torch.Size([5000, 16])\n",
      "torch.Size([2, 20, 10, 16])\n",
      "taille de x en sortie de l'encodeur : torch.Size([2, 200, 16])\n",
      "taille de x en sortie : torch.Size([2, 1, 200])\n"
     ]
    }
   ],
   "source": [
    "class TransfoDownscaling(nn.Module):\n",
    "    def __init__(self,full_data_size,embed_size,num_layers,heads,forward_expansion,dropout,max_length,input_size, hidden_size, output_size,):\n",
    "        super(TransfoDownscaling, self).__init__()\n",
    "        self.Encode = PersonalEncoder(full_data_size,embed_size,num_layers,heads,forward_expansion,dropout,max_length)\n",
    "        self.MLP = MLP(input_size, hidden_size, output_size)\n",
    "\n",
    "    def forward(self,x):\n",
    "        print('taille de x en entrée :',x.size())\n",
    "        x = self.Encode(x)\n",
    "        print(\"taille de x en sortie de l'encodeur :\",x.size())\n",
    "        x = self.MLP(x)\n",
    "        print('taille de x en sortie :',x.size())\n",
    "        return x\n",
    "\n",
    "        \n",
    "full_data_size=5000\n",
    "embed_size=16\n",
    "num_layers=2\n",
    "forward_expansion=4\n",
    "heads=8\n",
    "dropout=0\n",
    "max_length=5000\n",
    "model = TransfoDownscaling(full_data_size,embed_size,num_layers,heads,forward_expansion,dropout,max_length,input_size=embed_size, hidden_size=100, output_size=1)\n",
    "\n",
    "print(input_float.size())\n",
    "out= model(input_float)\n",
    "#print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8138b5b3-e6b6-448a-96d2-e3a7a01ee2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TRAINING :    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c80b1993-63cc-473e-820f-7f66a3367bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#size of input = torch.randint(0,20,(2,20,10,4)) #N=2,h=20,w=10,channels=4 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cbe2e07e-68ca-44b6-a5ab-67886a1525db",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/mberthier/repos/Downscaling_CM/data\"\n",
    "os.chdir(path)\n",
    "var_janv_fev=pd.read_csv('janvier_fevrier_variables_leman.csv')\n",
    "var_mars_avril=pd.read_csv('mars_avril_variables_leman.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0b392aa2-bf38-452d-8927-919963dba297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 60, 60, 4])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_cols = var_janv_fev[['rlon','rlat','temperature','humidity']]\n",
    "with_temp_jf = torch.tensor(selected_cols.values)\n",
    "selected_cols = var_mars_avril[['rlon','rlat','temperature','humidity']]\n",
    "with_temp_ma = torch.tensor(selected_cols.values)\n",
    "\n",
    "jf_input = with_temp_jf.reshape(60,60,4)\n",
    "ma_input = with_temp_ma.reshape(60,60,4)\n",
    "combined_input = torch.cat([jf_input.unsqueeze(0), ma_input.unsqueeze(0)], dim=0)\n",
    "combined_input.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0c764e64-f81b-4216-a6ee-421cba2ee546",
   "metadata": {},
   "outputs": [],
   "source": [
    "gev_params_janv_fev=pd.read_csv('gev_data_janv_fev.csv')\n",
    "gev_params_mars_avril=pd.read_csv('gev_data_mars_avril.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c53da443-0ce2-4ee6-bdfd-ca2455314754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60, 60, 22])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"/work/FAC/FGSE/IDYST/tbeucler/downscaling/mberthier/repos/Downscaling_CM/utils\"\n",
    "os.chdir(path)\n",
    "import dataset_for_R \n",
    "out_janv_fev = dataset_for_R.get_precipitation_CNN_size('janvier','fevrier',lon_bnd=(-2.6, -1.42),lat_bnd=(-0.6, 0.58))\n",
    "out_mars_avril=dataset_for_R.get_precipitation_CNN_size('mars','avril',lon_bnd=(-2.6, -1.42),lat_bnd=(-0.6, 0.58))\n",
    "\n",
    "out_janv_fev.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "da7c7202-38d1-4787-982d-a743c2b1eec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taille de x en entrée : torch.Size([2, 60, 60, 4])\n",
      "position size torch.Size([2, 60, 60])\n",
      "x torch.Size([2, 4, 60, 60])\n",
      "torch.Size([5000, 16])\n",
      "torch.Size([2, 60, 60, 16])\n",
      "taille de x en sortie de l'encodeur : torch.Size([2, 3600, 16])\n",
      "taille de x en sortie : torch.Size([2, 1, 3600])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 3600])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.double()\n",
    "model(combined_input).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8f801001-3cb4-4de4-be50-d3f7aac09842",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCRPSLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomCRPSLoss, self).__init__()\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        term_one = torch.mean(torch.abs(y_pred - y_true), dim=-1)\n",
    "        term_two = torch.mean(torch.abs(\n",
    "        torch.unsqueeze(y_pred, -1) - torch.unsqueeze(y_pred, -2)), dim=(-2, -1))\n",
    "        half = torch.tensor(-0.5, dtype=term_two.dtype)\n",
    "        loss = term_one + half * term_two\n",
    "        loss = torch.mean(loss)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "822c7aee-8a84-4089-be71-7357023c0aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taille de x en entrée : torch.Size([2, 60, 60, 4])\n",
      "position size torch.Size([2, 60, 60])\n",
      "x torch.Size([2, 4, 60, 60])\n",
      "torch.Size([5000, 16])\n",
      "torch.Size([2, 60, 60, 16])\n",
      "taille de x en sortie : torch.Size([2, 1, 3600])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m output\u001b[38;5;241m=\u001b[39mmodel(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m     15\u001b[0m batch_output \u001b[38;5;241m=\u001b[39m out_janv_fev\n\u001b[0;32m---> 16\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[43moutput\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     17\u001b[0m size \u001b[38;5;241m=\u001b[39m (output\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m],output\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m3\u001b[39m],batch_output\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m     19\u001b[0m u \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(size)\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 3"
     ]
    }
   ],
   "source": [
    "#x has size : [N,h,w,nb_features] while for CNN : [batch,channels,h,w]\n",
    "num_epoch = 5\n",
    "model=model.double()\n",
    "optimizer= torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "loss_crps=CustomCRPSLoss()\n",
    "loss_list=[]\n",
    "input = combined_input\n",
    "nb_lon=input.shape[2]\n",
    "nb_lat=input.shape[3]\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "\n",
    "    if epoch%2==0 :\n",
    "        output=model(input)\n",
    "        batch_output = out_janv_fev\n",
    "        loc = output[0,0,:,:]\n",
    "        size = (output.shape[2],output.shape[3],batch_output.shape[2])\n",
    "\n",
    "        u = torch.rand(size)\n",
    "        #print(size)\n",
    "        loc = loc.unsqueeze(-1).repeat(1, 1, size[2])\n",
    "        loc = torch.transpose(loc, 0, 1)\n",
    "        #print(loc.size())\n",
    "\n",
    "        ##On fixe xi et scale\n",
    "        \n",
    "        c = torch.tensor(gev_params_janv_fev['shape'])\n",
    "    \n",
    "        c = c.reshape(60, 60)\n",
    "        c = torch.transpose(c, 0,1) ##oujours 60,60\n",
    "        c = c.repeat(22,1,1)\n",
    "        c = torch.permute(c,(1,2,0))\n",
    "   \n",
    "        \n",
    "        scale = torch.tensor(gev_params_janv_fev['scale'])\n",
    "        scale = scale.reshape(60, 60)\n",
    "        scale = torch.transpose(scale, 0, 1)  # Toujours 60, 60\n",
    "        scale = scale.repeat(22, 1, 1)\n",
    "        scale = torch.permute(scale, (1, 2, 0))\n",
    "                \n",
    "        sample = loc + (torch.pow(-torch.log(u), -c) - 1) * scale / c\n",
    "        #print('sample',sample)\n",
    "       \n",
    "        loss1=loss_crps(sample,batch_output)\n",
    "        loss_list.append(torch.detach(loss1).numpy())\n",
    "        optimizer.zero_grad()\n",
    "        loss1.backward()\n",
    "        optimizer.step()\n",
    "    else : \n",
    "        output=model(input)\n",
    "        batch_output = out_mars_avril\n",
    "        loc = output[0,0,:,:]\n",
    "        size = (output.shape[2],output.shape[3],batch_output.shape[2])\n",
    "\n",
    "        u = torch.rand(size)\n",
    "\n",
    "        loc = loc.unsqueeze(-1).repeat(1, 1, size[2])\n",
    "        loc = torch.transpose(loc, 0, 1)\n",
    "        #print(loc.size())\n",
    "\n",
    "        ##On fixe xi et scale\n",
    "        \n",
    "        c = torch.tensor(gev_params_mars_avril['shape'])\n",
    "    \n",
    "        c = c.reshape(60, 60)\n",
    "        c = torch.transpose(c, 0,1) ##oujours 60,60\n",
    "        c = c.repeat(22,1,1)\n",
    "        c = torch.permute(c,(1,2,0))\n",
    "   \n",
    "        \n",
    "        scale = torch.tensor(gev_params_mars_avril['scale'])\n",
    "        scale = scale.reshape(60, 60)\n",
    "        scale = torch.transpose(scale, 0, 1)  # Toujours 60, 60\n",
    "        scale = scale.repeat(22, 1, 1)\n",
    "        scale = torch.permute(scale, (1, 2, 0))\n",
    "        \n",
    "        \n",
    "        sample = loc + (torch.pow(-torch.log(u), -c) - 1) * scale / c\n",
    "        #print('sample',sample)\n",
    "       \n",
    "        loss1=loss_crps(sample,batch_output)\n",
    "        loss_list.append(torch.detach(loss1).numpy())\n",
    "        optimizer.zero_grad()\n",
    "        loss1.backward()\n",
    "        optimizer.step()\n",
    "   \n",
    "    \n",
    "    if (epoch+1) % 5 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epoch}], Loss: {loss1.item():.4f}')\n",
    "\n",
    "plt.plot(loss_list[3:])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
